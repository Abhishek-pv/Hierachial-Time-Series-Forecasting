{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Karan\\Anaconda3\\envs\\forecast\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the true value dictionary from file\n",
    "gb_dict = pickle.load( open( \"store_class_dictionary_updated.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_del = []\n",
    "list_k = []\n",
    "list_r = []\n",
    "count = 0\n",
    "for key,val in gb_dict.items():\n",
    "        sales_df = val.values\n",
    "        index_df = val.index\n",
    "        df = pd.DataFrame(data = sales_df, index= index_df, columns = ['y'])\n",
    "        #year_\n",
    "        #count_year = df[df['y']==0].count()\n",
    "        year_df = val.loc[val.index<'2017'] \n",
    "        count_in_group = year_df[year_df['totalSales'] == 0]['totalSales'].count()\n",
    "        \n",
    "#         if count_in_group < 52*5*.3:\n",
    "#             list_del.append(key)\n",
    "        # thresholding on 50%: 1052\n",
    "        # thresholding on 30%: 969\n",
    "        \n",
    "        if count_in_group >= 250:\n",
    "            list_del.append(key)\n",
    "        \n",
    "#         df.drop(indexNames , inplace=True)\n",
    "#         tmp2 = df.groupby(df.index.year).agg(['count'])\n",
    "#         if 2015 in tmp2.index:\n",
    "#             k = tmp2.loc[2015].values\n",
    "#             list_k.append(k)\n",
    "#         if 2016 in tmp2.index:\n",
    "#             r = tmp2.loc[2016].values\n",
    "#             list_r.append(r)\n",
    "#         if (k+r) < 30:\n",
    "#             list_del.append(key)  \n",
    "#         Removed 889\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667\n"
     ]
    }
   ],
   "source": [
    "print(len(list_del))\n",
    "# for k, v in gb_dict.items():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero=1.5\n",
    "for key,val in gb_dict.items():\n",
    "        sales_df = val.values\n",
    "        index_df = val.index\n",
    "        df = pd.DataFrame(data = sales_df, index= index_df, columns = ['y'])\n",
    "        #indexNames = df[ df['y'] == 0 ].index\n",
    "        df = df.replace(to_replace = 0, value = zero) \n",
    "        neg_df = df.loc[df['y'] < 0] \n",
    "        index_drop = neg_df.index\n",
    "        final_df = df.drop(index_drop)\n",
    "        final_df['y'] = np.log(final_df['y'])\n",
    "        gb_dict[key] = final_df['y']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list_del:\n",
    "    del gb_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "with open(\"gb_dict_log_imputed.pickle\", \"wb\") as f:\n",
    "    pickle.dump(gb_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1550"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_sales)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing values further\n",
    "#creating dictionaries to store them as pickle files after training the model\n",
    "pred_sales = {}\n",
    "valid_sales= {}\n",
    "fcst_model = {}\n",
    "model_all2 = {}\n",
    "#training the Prophet model over each store-class combination\n",
    "for key,val in gb_dict.items():\n",
    "    sales_df = val.values\n",
    "    index_df = val.index\n",
    "    df = pd.DataFrame(data = sales_df, index= index_df, columns = ['y'])\n",
    "    # splitting data into training and validation in 75:25 ratio\n",
    "    train = df[0:260]\n",
    "    test = df[260:] \n",
    "    model = Prophet()\n",
    "    model.fit(train.reset_index().rename(columns={'index':'ds'}))\n",
    "    fcst = model.predict(df = test.reset_index().rename(columns={'index':'ds'}))\n",
    "    fcst_model[key] = fcst\n",
    "    y_pred = fcst['yhat']\n",
    "    y_test = test['y']\n",
    "    pred_sales[key] = y_pred\n",
    "    valid_sales[key] = y_test\n",
    "    model_all2[key] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "with open(\"store_class_imputed_log_noneg_model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model_all2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the true values of validation set\n",
    "with open(\"store_class_imputed_log_noneg_true.pickle\", \"wb\") as f:\n",
    "    pickle.dump(valid_sales, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the predicted values of validation set\n",
    "with open(\"store_class_dictionary_imputed_log_noneg_fcst_model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(fcst_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the predicted values of validation set\n",
    "with open(\"store_class_dictionary_imputed_log_noneg_pred_sales.pickle\", \"wb\") as f:\n",
    "    pickle.dump(pred_sales, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model dictionary from file\n",
    "md_pred2 = pickle.load( open( \"store_class_imputed_log_noneg_model.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the true value dictionary from file\n",
    "true_pred = pickle.load( open( \"store_class_imputed_log_noneg_true.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the predicted value dictionary from file\n",
    "fcst_pred = pickle.load( open( \"store_class_dictionary_imputed_log_noneg_fcst_model.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the predicted value dictionary from file\n",
    "pred_sal = pickle.load( open( \"store_class_dictionary_imputed_log_noneg_pred_sales.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists for plotting\n",
    "lt4 = list(true_pred.values())\n",
    "test1 = lt4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list(map(list,true_pred.values()))\n",
    "j = list(map(list, pred_sal.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(s[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(s)):\n",
    "    z.append(np.exp(s[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "for i in range(0,len(j)):\n",
    "    w.append(np.exp(j[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating mse and mae\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = []\n",
    "mae = []\n",
    "for i in range(0,len(w)):\n",
    "    mse.append(mean_squared_error(y_true=z[i],y_pred=w[i]))\n",
    "    mae.append(mean_absolute_error(y_true=z[i],y_pred=w[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating mape\n",
    "mape = []\n",
    "zero=1e-24\n",
    "def mean_absolute_percentage_error2(y_true, y_pred): \n",
    "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true+zero))) * 100\n",
    "for i in range(0,len(w)):\n",
    "    mape.append(mean_absolute_percentage_error2(y_true=z[i],y_pred=w[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving evaluation metrics to csv via dataframe\n",
    "df2 = pd.DataFrame(list(zip(mse, mae,mape)), columns =['MSE', 'MAE', 'MAPE']) \n",
    "df2.to_csv('evaluation_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt3 = list(pred_sal.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using the summation matrix to get predictions of every combination in the hierarchy\n",
    "summation = pickle.load(open(\"agg_combo.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing one leaf node\n",
    "b = lt3[0]\n",
    "b = b.to_numpy()\n",
    "b = b.reshape(-1,53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining other leaf nodes\n",
    "for i in range(1,len(lt3)):\n",
    "    numpy_b = lt3[i].to_numpy()\n",
    "    numpy_s = numpy_b.reshape(-1,53)\n",
    "    b = np.append(b, numpy_s, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to numpy for enabling multiplication\n",
    "S_arr = summation.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the predictions\n",
    "ypred = np.dot(S_arr,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#does not give good result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
